{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61883625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, List, Optional, Any\n",
    "import langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1ecbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoProfile(BaseModel):\n",
    "    name: str\n",
    "    skills: List[str] = []\n",
    "    experience: int = 0\n",
    "    price: int = 0\n",
    "    description: str = \"\"\n",
    "\n",
    "class Jobdescription(BaseModel):\n",
    "    post_title: str = \"\"\n",
    "    post_description: str = \"\"\n",
    "    post_skills_founded: List[str] = []\t\n",
    "    skills_asked_expliced: Optional[List[str]] = []\n",
    "    level_asked: Optional[str] = \"\"\n",
    "\n",
    "class ProposalState(BaseModel):\n",
    "    headline: str = Field(..., description=\"Fist Line of the Proposal. Shuld get the attention of the client.\")\n",
    "    body: str = Field(..., description=\"Body of the Proposal. Should contain the details of the proposal.\")\n",
    "    full_text:str = Field(..., description=\"Full text of the Proposal.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "505036cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_post_tile = \"\"\"Client Trend Analysis and Credit Approval Automation\"\"\"\n",
    "job_description = \"\"\"Project Objectives\n",
    "1. Client Trend Analysis\n",
    "‚Ä¢ Identify behavioral and demographic trends in our customer base.\n",
    "‚Ä¢ Group similar client profiles (segmentation/clustering).\n",
    "‚Ä¢ Predict client purchase behavior and potential lifetime value.\n",
    "2. AI-Driven Credit Evaluation\n",
    "‚Ä¢ Analyze submitted application data (income, occupation, credit history, references, etc.).\n",
    "‚Ä¢ Integrate with internal/external data sources to enhance decision accuracy.\n",
    "‚Ä¢ Create a scoring model for automated or assisted credit approvals.\n",
    "3. Dashboard & Integration\n",
    "‚Ä¢ Create a user-friendly dashboard to visualize trends and approve/reject applications.\n",
    "‚Ä¢ Optional: Integrate with our existing systems (CRM, Excel, SAP).\n",
    "Scope of Work\n",
    "‚Ä¢ Data audit and ingestion\n",
    "‚Ä¢ AI/ML model development (client clustering, credit scoring)\n",
    "‚Ä¢ Model testing and validation\n",
    "‚Ä¢ Dashboard for credit review and trend insights\n",
    "‚Ä¢ Basic team training and documentation\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cfb4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_headline = \"\"\"Data Scientist | LLM/Machine Learning | 10+ Million Saved Using AI\"\"\"\n",
    "profile_summary = \"\"\"\n",
    "Struggling to make data-driven decisions that truly impact revenue? You know your business needs to leverage AI and machine learning, but you're unsure how to implement it effectively.\n",
    "I specialize in transforming raw data into actionable insights that drive real financial results.\n",
    "What people I work with say about me:\n",
    "\n",
    "üèÖ\"Italo is one of the most talented and impactful professionals I've worked with. He not only brings technical prowess but also a sharp business acumen that drives real value.\" ‚Äì Igor Aboim, Staff Data Scientist\n",
    "üèÖ\"His expertise in building dashboards and managing data operations has consistently optimized our processes. A truly excellent professional.\" ‚Äì Viviane Ghedini\n",
    "üèÖ\"I highly recommend Italo for his outstanding work in database management, performance analysis, and campaign optimization.\" ‚Äì Marcus Plaisant\n",
    "\n",
    "Here's what I've done for my clients and employers:\n",
    "\n",
    "ü§ñ Multi-Agent AI System for Heineken Brazil: Developed a WhatsApp-based voice collection system that processes 2,000+ daily sales reports, analyzing 10,000+ hours of audio monthly to deliver real-time competitive intelligence across the entire country.\n",
    "üí∞ Reduced absenteeism costs by $1M+/year using predictive modeling.\n",
    "üîç Developed AI-powered anomaly detection, saving $10M+ annually for Heineken Brazil.\n",
    "üìà Increased e-commerce ROAS by 30% through Marketing Mix Modeling.\n",
    "ü§ñ Designed and deployed Generative AI agents for HR automation and compliance validation.\n",
    "\n",
    "We're a great fit if you're thinking:\n",
    "\n",
    "üí≠ \"We have data but don't know how to maximize its value.\"\n",
    "üí≠ \"We need an AI expert who understands business impact, not just algorithms.\"\n",
    "üí≠ \"I want scalable, automated solutions‚Äînot just reports and dashboards.\"\n",
    "üí≠ \"I don't have time to learn data science. I need someone to execute and deliver.\"\n",
    "\n",
    "Working with me, you'll get:\n",
    "\n",
    "üîÆ Predictive models that increase efficiency and cut costs.\n",
    "‚öôÔ∏è AI-powered automation that eliminates manual work.\n",
    "üîÑ End-to-end solutions‚Äîfrom data pipeline setup to model deployment.\n",
    "üìä AI-driven marketing insights to optimize ad spend and revenue.\n",
    "My expertise includes:\n",
    "üß† Machine Learning & AI: Python, XGBoost, NLP, LLMs, LangChain, LangGraph, LLMops, Multi-agent systems\n",
    "üîß Data Engineering: SQL, Databricks, Google Cloud, Azure, BigQuery, Azure OpenAI\n",
    "üìä Marketing Analytics: Marketing Mix Modeling, Campaign Optimization, Competitive Intelligence\n",
    "üìà Business Intelligence: Power BI, Looker Studio, Automated Insights\n",
    "\n",
    "Ready to unlock the full potential of your data? Click \"Invite to Job\" and let's discuss how I can help your business grow through AI and data science!\n",
    "\"\"\"\n",
    "\n",
    "protifolio = \"\"\"\n",
    "Multi-Agent AI: Processing 2K+ Daily Sales Reports for Heineken: \n",
    "Built a frictionless market intelligence solution for Heineken Brazil \n",
    "using WhatsApp voice notes from field representatives. Implemented a multi-agent AI \n",
    "system with LangGraph and Azure OpenAI that automatically extracts and structures \n",
    "competitive insights from audio recordings. Now processing inputs from 2,000+ reps and \n",
    "analyzing 10,000+ audio hours monthly, providing real-time.\n",
    "\n",
    "Saved $10M+ with Advanced Anomaly Detection for Heineken Brazil:\n",
    "Developed an advanced anomaly detection system for Heineken Brazil \n",
    "that automatically identifies root causes of financial losses across product/region combinations.\n",
    "By implementing a two-layer approach combining statistical outlier detection and causal inference \n",
    "with SHAP values, I expanded analysis capacity from 25 to 600+ combinations monthly. \n",
    "This solution enabled rapid identification of loss drivers, resulting in \n",
    "$10M+ annual savings while providing actionable insights for business stakeholders.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d7e5a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c95efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8987a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8bb80a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"qwen-2.5-32b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a86db0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_needed = [\n",
    "    \"Generative AI expertise\",\n",
    "    \"AI automation knowledge\",\n",
    "    \"Content creation skills (for a 30-second commercial)\",\n",
    "    \"Scriptwriting skills (for a catchy hook and commercial script)\",\n",
    "    \"Understanding of AI applications in business (specifically lead generation and conversion)\",\n",
    "    \"Familiarity with SMS and voice automation technologies\",\n",
    "    \"Knowledge of ROI analysis and metrics (to understand 90% ROI increase)\",\n",
    "    \"Creative problem-solving skills (to 'turn cold leads hot again')\",\n",
    "    \"Collaboration and partnership skills (to work as a 'right-hand partner')\",\n",
    "    \"Communication skills (to effectively convey the value proposition of the AI automation)\"\n",
    "]\n",
    "\n",
    "pain_points = [\n",
    " \"Low conversion rates of leads into booked appointments\",\n",
    " \"Difficulty in engaging with leads in a timely manner\",\n",
    " \"Loss of potential revenue due to leads slipping through the cracks\",\n",
    " \"Need to effectively communicate the value proposition of their AI automation solution to potential clients\",\n",
    " \"Desire to increase revenue and ROI for their business and their clients\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea17f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skills(llm, job_description, job_post_tile):\n",
    "    class SkillsFormater(BaseModel):\n",
    "        skills: List[str] = []\n",
    "\n",
    "    skill_stractor_prompt = f\"\"\"\n",
    "    Bellow is a Upwork job description. \n",
    "    Extract Skills needed to perform the job from the following job description:\n",
    "\n",
    "    <job_title>\n",
    "    {job_post_tile}\n",
    "    </job_title>\n",
    "\n",
    "    <job_description>\n",
    "    {job_description}\n",
    "    </job_description>\n",
    "    \"\"\"\n",
    "    skill_prompt = [\n",
    "        ('system', skill_stractor_prompt),\n",
    "        ('user', \"return a python list of the skills needed\")\n",
    "    ]\n",
    "    skills_structured_llm = llm.with_structured_output(SkillsFormater)\n",
    "    skills_needed = skills_structured_llm.invoke(skill_prompt)\n",
    "    return skills_needed\n",
    "\n",
    "def get_pain_points(llm, job_description, job_post_tile):\n",
    "    class PainPointsFormater(BaseModel):\n",
    "        pain_points: List[str] = []\n",
    "    \n",
    "    client_motivations_prompt= f\"\"\" \n",
    "    Extract the client motivations from the following upwork job description:\n",
    "    - Considere why the client is looking for a freelancer\n",
    "    - Identify the main pain points that the client is facing that lead him to post a job.\n",
    "    - Consider not only the pain points mentioned in the job description, but also the underlying issues that the client is facing.\n",
    "\n",
    "    <job_title>\n",
    "    {job_post_tile}\n",
    "    </job_title>\n",
    "\n",
    "    <job_description>\n",
    "    {job_description}\n",
    "    </job_description>\n",
    "    \"\"\"\n",
    "\n",
    "    pain_prompt = [\n",
    "        ('system', client_motivations_prompt),\n",
    "        ('user', \"return a python list of the pain points\")\n",
    "    ]\n",
    "    pain_points_structured_llm = llm.with_structured_output(PainPointsFormater)\n",
    "    pain_points = pain_points_structured_llm.invoke(pain_prompt)\n",
    "    return pain_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5454f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting_arguments(llm, profile_headline, profile_summary, protifolio, pain_points, skills_needed):\n",
    "    selecting_arguments_prompt = f\"\"\"\n",
    "    Based on the my information prifile, select witch of the pain ponts and skills that I can help with.\n",
    "    - Take into account my protifolio and my profile summary.\n",
    "    - Analyze how I can help with the pain points and skills needed.\n",
    "    - If a pain point is not related to my skills, ignore it.\n",
    "\n",
    "    <profile>\n",
    "        <profile_headline>\n",
    "        {profile_headline}\n",
    "        </profile_headline>\n",
    "        <profile_summary>\n",
    "        {profile_summary}\n",
    "        </profile_summary>\n",
    "        <protifolio>\n",
    "        {protifolio}\n",
    "        </protifolio>\n",
    "    </profile>\n",
    "\n",
    "\n",
    "    <pain_points>\n",
    "    {pain_points}\n",
    "    </pain_points>\n",
    "\n",
    "    <skills_needed>\n",
    "    {skills_needed}\n",
    "    </skills_needed>\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    class SelectedArguments(BaseModel):\n",
    "        arguments: List[Any] = Field(..., description=\"List of arguments showing how I can help with each pain point or skill\")\n",
    "    \n",
    "    selected_arguments_prompt = [\n",
    "        ('system', selecting_arguments_prompt),\n",
    "        ('user', \"Return a json of the pain points/skills that I can help with. The keys should be the pain points/skills and the values should be a brief description of how I can help with it. Be specific and persuasive. You can select exemples our of my protifolio.\")\n",
    "    ]\n",
    "    selected_arguments_structured_llm = llm.with_structured_output(SelectedArguments)\n",
    "    selected_arguments = selected_arguments_structured_llm.invoke(selected_arguments_prompt)\n",
    "    return selected_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98840202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecting_arguments(llm, profile_headline, profile_summary, protifolio, pain_points, skills_needed):\n",
    "    class Argument(BaseModel):\n",
    "        pain_point: str = Field(..., description=\"The client's pain point or required skill\")\n",
    "        solution: str = Field(..., description=\"How I can address this need based on my experience\")\n",
    "\n",
    "    class SelectedArguments(BaseModel):\n",
    "        arguments: List[Argument] = Field(..., description=\"List of matching arguments between my experience and client needs\")\n",
    "\n",
    "    selecting_arguments_prompt = f\"\"\"\n",
    "    Create specific matches between the client's needs and my experience.\n",
    "    \n",
    "    Profile Information:\n",
    "    Headline: {profile_headline}\n",
    "    Summary: {profile_summary}\n",
    "    Portfolio: {protifolio}\n",
    "\n",
    "    Client Needs:\n",
    "    Pain Points: {pain_points}\n",
    "    Required Skills: {skills_needed}\n",
    "\n",
    "    For each key client need, provide:\n",
    "    1. The specific pain point or skill needed\n",
    "    2. How my experience directly addresses it, with concrete examples\n",
    "    \"\"\"\n",
    "    \n",
    "    selected_arguments_prompt = [\n",
    "        ('system', selecting_arguments_prompt),\n",
    "        ('user', \"\"\"Return a list of arguments in this format:\n",
    "        {\n",
    "            \"arguments\": [\n",
    "                {\n",
    "                    \"pain_point\": \"specific need\",\n",
    "                    \"solution\": \"how I address it with specific example\"\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "        Include 3-4 strongest matches.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        selected_arguments_structured_llm = llm.with_structured_output(SelectedArguments)\n",
    "        return selected_arguments_structured_llm.invoke(selected_arguments_prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in structured output: {str(e)}\")\n",
    "        # Return a default structured response\n",
    "        return SelectedArguments(arguments=[\n",
    "            Argument(\n",
    "                pain_point=\"Error processing response\",\n",
    "                solution=\"Please try running the query again\"\n",
    "            )\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6555c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = get_skills(llm, job_description, job_post_tile)\n",
    "pain_points = get_pain_points(llm, job_description, job_post_tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f01fa54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lack of insight into client behavior and demographics',\n",
       " 'Inefficient credit evaluation process',\n",
       " 'Need for automated decision-making',\n",
       " 'Data integration challenges',\n",
       " 'Lack of user-friendly visualization tools',\n",
       " 'Training and documentation needs']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pain_points.pain_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbc5ddbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analysis',\n",
       " 'Machine Learning',\n",
       " 'AI',\n",
       " 'Predictive Modeling',\n",
       " 'Credit Scoring',\n",
       " 'Data Visualization',\n",
       " 'Dashboard Creation',\n",
       " 'Python Programming',\n",
       " 'SQL',\n",
       " 'Data Integration',\n",
       " 'Clustering',\n",
       " 'CRM Integration',\n",
       " 'Excel Integration',\n",
       " 'SAP Integration']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills.skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6704d36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pain Point: Lack of insight into client behavior and demographics\n",
      "Solution: I developed an AI-powered anomaly detection system for Heineken Brazil that provides real-time insights into sales and market behavior, helping to identify trends and anomalies in client behavior and demographics.\n",
      "\n",
      "Pain Point: Inefficient credit evaluation process\n",
      "Solution: I have experience in predictive modeling and machine learning, which can be applied to create a more efficient credit scoring model. For instance, I used predictive modeling to reduce absenteeism costs by $1M+/year, demonstrating my ability to optimize processes through data-driven solutions.\n",
      "\n",
      "Pain Point: Need for automated decision-making\n",
      "Solution: I designed and deployed a multi-agent AI system for Heineken Brazil that automates the collection and analysis of sales reports, enabling real-time decision-making based on structured data inputs from 2,000+ field representatives.\n",
      "\n",
      "Pain Point: Data integration challenges\n",
      "Solution: I have extensive experience in data engineering, including working with SQL, Databricks, Google Cloud, and Azure. I can integrate various data sources and build robust data pipelines to ensure seamless data flow and accessibility.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "arguments = selecting_arguments(llm, profile_headline, profile_summary, protifolio, pain_points.pain_points, skills.skills)\n",
    "\n",
    "# Access the results\n",
    "for arg in arguments.arguments:\n",
    "    print(f\"\\nPain Point: {arg.pain_point}\")\n",
    "    print(f\"Solution: {arg.solution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00e8f2b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SelectedArguments\narguments\n  Input should be a valid list [type=list_type, input_value={'Lack of insight into cl...gs and revenue growth.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m arguments = \u001b[43mselecting_arguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_headline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotifolio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpain_points\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpain_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskills\u001b[49m\u001b[43m.\u001b[49m\u001b[43mskills\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mselecting_arguments\u001b[39m\u001b[34m(llm, profile_headline, profile_summary, protifolio, pain_points, skills_needed)\u001b[39m\n\u001b[32m     34\u001b[39m selected_arguments_prompt = [\n\u001b[32m     35\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m'\u001b[39m, selecting_arguments_prompt),\n\u001b[32m     36\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mReturn a json of the pain points/skills that I can help with. The keys should be the pain points/skills and the values should be a brief description of how I can help with it. Be specific and persuasive. You can select exemples our of my protifolio.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m ]\n\u001b[32m     38\u001b[39m selected_arguments_structured_llm = llm.with_structured_output(SelectedArguments)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m selected_arguments = \u001b[43mselected_arguments_structured_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_arguments_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m selected_arguments\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/upwork_proposal_generator/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/upwork_proposal_generator/.venv/lib/python3.13/site-packages/langchain_core/output_parsers/base.py:196\u001b[39m, in \u001b[36mBaseOutputParser.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/upwork_proposal_generator/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:1933\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1929\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1930\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1931\u001b[39m         output = cast(\n\u001b[32m   1932\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1933\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1935\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1936\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1937\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1938\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1939\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1940\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1941\u001b[39m         )\n\u001b[32m   1942\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1943\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/upwork_proposal_generator/.venv/lib/python3.13/site-packages/langchain_core/runnables/config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/upwork_proposal_generator/.venv/lib/python3.13/site-packages/langchain_core/output_parsers/base.py:197\u001b[39m, in \u001b[36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[39m\u001b[34m(inner_input)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    190\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    193\u001b[39m     **kwargs: Any,\n\u001b[32m    194\u001b[39m ) -> T:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    200\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    201\u001b[39m             config,\n\u001b[32m    202\u001b[39m             run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    203\u001b[39m         )\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_with_config(\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m.parse_result([Generation(text=inner_input)]),\n\u001b[32m    206\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    207\u001b[39m         config,\n\u001b[32m    208\u001b[39m         run_type=\u001b[33m\"\u001b[39m\u001b[33mparser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    209\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/upwork_proposal_generator/.venv/lib/python3.13/site-packages/langchain_core/output_parsers/openai_tools.py:295\u001b[39m, in \u001b[36mPydanticToolsParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     pydantic_objects.append(\u001b[43mname_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43margs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationError, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m    297\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m partial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/upwork_proposal_generator/.venv/lib/python3.13/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for SelectedArguments\narguments\n  Input should be a valid list [type=list_type, input_value={'Lack of insight into cl...gs and revenue growth.'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type"
     ]
    }
   ],
   "source": [
    "arguments = selecting_arguments(llm, profile_headline, profile_summary, protifolio, pain_points.pain_points, skills.skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491bd186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pain_point': 'Need to understand customer behavior and demographics to improve marketing and sales strategies.',\n",
       " 'description': 'I can develop AI models using machine learning techniques to analyze customer behavior and demographics. By leveraging my expertise in Marketing Analytics and AI, I can create predictive models that identify key customer segments and their behaviors, enabling you to tailor marketing and sales strategies for maximum impact. For example, I have successfully used Marketing Mix Modeling to optimize ad spend and revenue for previous clients.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments.arguments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd4c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
